{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanPellegrini11/Aprendizaje_por_refuerzos_taximetro/blob/main/Aprendizaje_por_refuerzos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77Zx5A4LW2kX"
      },
      "source": [
        "Importamos la biblioteca Gymnassium, que vamos a usar como framework de RL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DMNlTOdW2ka"
      },
      "outputs": [],
      "source": [
        "!pip3 install cmake gymnasium scipy\n",
        "import gymnasium as gym"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi-bWbYYW2kb"
      },
      "source": [
        "Creamos un ambiente y lo mostramos en pantalla. Para esto definimos una función para imprimir nuestro ambiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRRQskBUW2kc"
      },
      "outputs": [],
      "source": [
        "# La semilla usada para crear el ambiente\n",
        "semilla = 1\n",
        "\n",
        "entorno = gym.make(\"Taxi-v3\", render_mode='ansi').env\n",
        "entorno.reset(seed = semilla)\n",
        "\n",
        "# Una funcion de ayuda para imprimir el estado de nuestro mundo\n",
        "def print_env(estado):\n",
        "  env_str = estado.render()\n",
        "  print(env_str)\n",
        "\n",
        "print_env(entorno)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBHMZignW2kc"
      },
      "source": [
        "\n",
        "El rectángulo de color representa el taxi, amarillo cuando va sin pasajero y verde con pasajero.\n",
        "'|' representa una pared que el taxi no puede cruzar, es decir.\n",
        "R, G, Y, B son los puntos de interés, es decir, las posibles ubicaciones de recogida y destino. La letra azul representa la ubicación actual de recogida de pasajeros, y la letra púrpura es el destino actual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxsJZWB4W2kc"
      },
      "source": [
        "Si cambiamos la semilla, cambia el estado del ambiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDPjHXMjW2kc"
      },
      "outputs": [],
      "source": [
        "# Una semilla diferente\n",
        "semilla = 2\n",
        "\n",
        "entorno = gym.make(\"Taxi-v3\", render_mode='ansi').env\n",
        "entorno.reset(seed = semilla)\n",
        "\n",
        "print_env(entorno)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9XhVz3-W2kd"
      },
      "source": [
        "Exploremos el espacio de estados y de acciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnEJJ2uYW2kd"
      },
      "outputs": [],
      "source": [
        "print(f\"Espacio de Acciones {entorno.action_space}\")\n",
        "print(f\"Espacio de Estados {entorno.observation_space}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXoEkPOjW2ke"
      },
      "source": [
        "Hay 6 acciones, que corresponden a:\n",
        " * 0 = ir al Sur\n",
        " * 1 = ir al Norte\n",
        " * 2 = ir al Este\n",
        " * 3 = ir al Oeste\n",
        " * 4 = recoger pasajero\n",
        " * 5 = dejar pasajero\n",
        "\n",
        "Los puntos cardinales siguen la convención Norte hacie arriba. Recoger/dejar al pasajero solo tienen efecto si el taxi está en la misma casilla que el pasajero, y en uno de los puntos de interés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXKTc22_W2ke"
      },
      "source": [
        "Nuestro agente deberá elegir la acción a tomar en cada paso. Gymnassium nos expone funciones para esto. Si queremos movernos al sur, por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GZcAkDOW2ke"
      },
      "outputs": [],
      "source": [
        "semilla = 1\n",
        "entorno = gym.make(\"Taxi-v3\", render_mode='ansi').env\n",
        "entorno.reset(seed = semilla)\n",
        "print_env(entorno)\n",
        "\n",
        "accion = 0 # Sur\n",
        "entorno.step(accion)\n",
        "\n",
        "print_env(entorno)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akFHZ-A0W2kf"
      },
      "source": [
        "Ahora estamos listos para programar un agente. Empezando por uno random. Se puede ejecutar el codigo abajo varias veces para ver como cambia en cada ejecución, debido a que la semilla_acciones es diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYSJ0GtdW2kf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def episodio_random(semilla_ambiente = 1):\n",
        "    entorno = gym.make(\"Taxi-v3\", render_mode='ansi').env\n",
        "    entorno.reset(seed = semilla_ambiente)\n",
        "\n",
        "    iteraciones = 0\n",
        "    penalizaciones, recompensa = 0, 0\n",
        "\n",
        "    marcos = [] # para la animación\n",
        "\n",
        "    termino = False\n",
        "    truncado = False\n",
        "\n",
        "    while not termino and not truncado:\n",
        "        #  selecciona una acción aleatoria del conjunto de todas las posibles acciones\n",
        "        accion = entorno.action_space.sample()\n",
        "        estado, recompensa, termino, truncado, info = entorno.step(accion)\n",
        "\n",
        "        # El agente trato de dejar/recoger al pasajero incorrectamente\n",
        "        if recompensa == -10:\n",
        "            penalizaciones += 1\n",
        "\n",
        "        # Put each rendered frame into dict for animation\n",
        "        marcos.append({\n",
        "            'marco': entorno.render(),\n",
        "            'estado': estado,\n",
        "            'accion': accion,\n",
        "            'recompensa': recompensa\n",
        "            }\n",
        "        )\n",
        "\n",
        "        iteraciones += 1\n",
        "\n",
        "\n",
        "    print(\"Iteraciones: {iteraciones}\")\n",
        "    print(\"Penalizaciones: {penalizaciones}\")\n",
        "\n",
        "    return marcos\n",
        "\n",
        "marcos = episodio_random()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxM_ApubW2kf"
      },
      "source": [
        "Podemos ver el episodio completo abajo. Notar que seleccionamos la semillia de selector de acciones para que la corrida sea 'buena'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWUwnkQFW2kf"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "import sys\n",
        "\n",
        "def print_frames(marcos):\n",
        "    for i, marco in enumerate(marcos):\n",
        "        clear_output()\n",
        "        print(marco['marco'])\n",
        "        print(f\"Iteracion: {i + 1}\")\n",
        "        print(f\"Estado: {marco['estado']}\")\n",
        "        print(f\"Accion: {marco['accion']}\")\n",
        "        print(f\"Recompensa: {marco['recompensa']}\")\n",
        "        sys.stdout.flush()\n",
        "        # Aumentar este tiempo para ver mejor la animación\n",
        "        sleep(.01)\n",
        "\n",
        "print_frames(marcos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc80pEq_W2kf"
      },
      "source": [
        "Ahora queremos programar un agente inteligente, para eso nos vamos a atener a la siguiente interfaz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX0ChvESW2kg"
      },
      "outputs": [],
      "source": [
        "class Agente:\n",
        "    def elegir_accion(self, estado, max_accion) -> int:\n",
        "        \"\"\"Elegir la accion a tomar en el estado actual y el espacio de acciones\"\"\"\n",
        "        pass\n",
        "\n",
        "    def aprender(self, estado_anterior, estado_siguiente, accion, recompensa):\n",
        "        \"\"\"Aprender a partir de la tupla\n",
        "            - estado_anterior: el estado desde que se empezó\n",
        "            - estado_siguiente: el estado al que se llegó\n",
        "            - accion: la acción que llevo al agente desde estado_anterior a estado_siguiente\n",
        "            - recompensa: la recompensa recibida en la transicion\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKf1W04IW2kg"
      },
      "source": [
        "Para nuestro agente aleatorio, esto sería:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt1f81d6W2kg"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class AgenteAleatorio(Agente):\n",
        "    def elegir_accion(self, estado, max_accion) -> int:\n",
        "        # Elige una acción al azar\n",
        "        return random.randrange(max_accion)\n",
        "\n",
        "    def aprender(self, estado_anterior, estado_siguiente, accion, recompensa):\n",
        "        # No aprende\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiqfJimvW2kg"
      },
      "source": [
        "Poniendolo a jugar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtNsEEDPW2kh"
      },
      "outputs": [],
      "source": [
        "semilla = 1\n",
        "entorno = gym.make(\"Taxi-v3\", render_mode='ansi').env\n",
        "\n",
        "agente = AgenteAleatorio()\n",
        "\n",
        "iteraciones = 0\n",
        "penalizaciones, recompensa = 0, 0\n",
        "\n",
        "marcos = [] # for animation\n",
        "\n",
        "termino = False\n",
        "truncado = False\n",
        "estado_anterior, info = entorno.reset(seed = semilla)\n",
        "while not termino and not truncado:\n",
        "    # Le pedimos al agente que elija entre las posibles acciones (0..entorno.action_space.n)\n",
        "    accion = agente.elegir_accion(estado_anterior, entorno.action_space.n)\n",
        "    # Realizamos la accion\n",
        "    estado_siguiente, recompensa, termino, truncado, info = entorno.step(accion)\n",
        "    # Le informamos al agente para que aprenda\n",
        "    agente.aprender(estado_anterior, estado_siguiente, accion, recompensa)\n",
        "\n",
        "    # El agente trato de dejar/recoger al pasajero incorrectamente\n",
        "    if recompensa == -10:\n",
        "        penalizaciones += 1\n",
        "\n",
        "    # Put each rendered frame into dict for animation\n",
        "    marcos.append({\n",
        "        'marco': entorno.render(),\n",
        "        'estado': estado_siguiente,\n",
        "        'accion': accion,\n",
        "        'recompensa': recompensa\n",
        "        }\n",
        "    )\n",
        "\n",
        "    estado_anterior = estado_siguiente\n",
        "    iteraciones += 1\n",
        "\n",
        "\n",
        "print(f\"Iteraciones: {iteraciones}\")\n",
        "print(f\"Penalizaciones: {penalizaciones}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxxJYwRGW2kh"
      },
      "source": [
        "Podemos encapsular lo anterior en una función"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TriDM-xvW2kh"
      },
      "outputs": [],
      "source": [
        "def ejecutar_episodio(agente, semilla):\n",
        "    entorno = gym.make(\"Taxi-v3\", render_mode='ansi').env\n",
        "\n",
        "    iteraciones = 0\n",
        "    penalizaciones, recompensa = 0, 0\n",
        "\n",
        "    marcos = [] # for animation\n",
        "\n",
        "    termino = False\n",
        "    truncado = False\n",
        "    estado_anterior, info = entorno.reset(seed = semilla)\n",
        "    while not termino and not truncado:\n",
        "        # Le pedimos al agente que elija entre las posibles acciones (0..entorno.action_space.n)\n",
        "        accion = agente.elegir_accion(estado_anterior, entorno.action_space.n)\n",
        "        # Realizamos la accion\n",
        "        estado_siguiente, recompensa, termino, truncado, info = entorno.step(accion)\n",
        "        # Le informamos al agente para que aprenda\n",
        "        agente.aprender(estado_anterior, estado_siguiente, accion, recompensa)\n",
        "\n",
        "        # El agente trato de dejar/recoger al pasajero incorrectamente\n",
        "        if recompensa == -10:\n",
        "            penalizaciones += 1\n",
        "\n",
        "        # Put each rendered frame into dict for animation\n",
        "        marcos.append({\n",
        "            'marco': entorno.render(),\n",
        "            'estado': estado_siguiente,\n",
        "            'accion': accion,\n",
        "            'recompensa': recompensa\n",
        "            }\n",
        "        )\n",
        "\n",
        "        estado_anterior = estado_siguiente\n",
        "        iteraciones += 1\n",
        "    return iteraciones\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAVl9XP7W2kh"
      },
      "source": [
        "y correrlo varias veces para ver el rendimiento promedio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeOOIqsdW2ki"
      },
      "outputs": [],
      "source": [
        "agente = AgenteAleatorio()\n",
        "semilla = 1\n",
        "num_iteraciones_episodios = []\n",
        "for i in range(10):\n",
        "    num_iteraciones = ejecutar_episodio(agente, semilla)\n",
        "    num_iteraciones_episodios += [num_iteraciones]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqXUwSzmW2ki"
      },
      "source": [
        "Y obtener métricas al respecto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTh8EPwjW2ki"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "print(f\"Se realizaron {numpy.mean(num_iteraciones_episodios)}, en promedio\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcPON3VEW2ki"
      },
      "source": [
        "La tarea a realizar consiste en programar un agente de aprendizaje por refuerzos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0u1yh-OW2ki"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class AgenteRL(Agente):\n",
        "    # Agregar código aqui\n",
        "\n",
        "    def __init__(self, entorno) -> None:\n",
        "        super().__init__()\n",
        "        # Agregar código aqui\n",
        "\n",
        "    def elegir_accion(self, estado, max_accion) -> int:\n",
        "        # Agregar código aqui\n",
        "        return 0\n",
        "\n",
        "    def aprender(self, estado_anterior, estado_siguiente, accion, recompensa):\n",
        "        # Agregar código aqui\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f89U54fW2ki"
      },
      "source": [
        "Y ejecutar con el muchos episodios con la misma semilla:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSZHhm8xW2ki"
      },
      "outputs": [],
      "source": [
        "# Advertencia: este bloque es un loop infinito si el agente se deja sin implementar\n",
        "\n",
        "agente = AgenteRL(entorno)\n",
        "semilla = 1\n",
        "num_iteraciones_episodios = []\n",
        "for i in range(1000):\n",
        "    num_iteraciones = ejecutar_episodio(agente, semilla)\n",
        "    num_iteraciones_episodios += [num_iteraciones]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9eGLupxW2kj"
      },
      "source": [
        "Analizar los resultados de la ejecución anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zdX8s9UW2kj"
      },
      "outputs": [],
      "source": [
        "# Analizar los resultados aqui\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo6RN7D6W2kj"
      },
      "source": [
        "Se mantiene el rendimiento si cambiamos la semilla? Por qué?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs2Xd6_CW2kj"
      },
      "outputs": [],
      "source": [
        "# Agregar código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWKqGwS3W2kj"
      },
      "source": [
        "Podemos mejorar el agente para que se desempeñe bien usando cualquier semilla?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy7Qcb_LW2kj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Agregar código aqui\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}